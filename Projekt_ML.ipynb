{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projekt ML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GNyRHa5X4Pfl",
        "V1AZUQ3fb7c6",
        "haNgZMiW4Ewe",
        "fL7YQvk59gqj",
        "gIPcwfNUjIv0"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fblazejewski/Przewidywanie-sredniej-filmow/blob/master/Projekt_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNyRHa5X4Pfl",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#Klasa przechowująca dane + parser stron tworzący baze filmów"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TundJY7_EeNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import re\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import json\n",
        "import sys\n",
        "\n",
        "class Data:\n",
        "  frame = pd.DataFrame()\n",
        "\n",
        "  def createData(self, limit=0):\n",
        "    links = self._grabLinks(limit)\n",
        "    for link in links:\n",
        "      newDF = self._getDataFrame(link)\n",
        "      if newDF is not None:\n",
        "        self.frame = pd.concat([self.frame, newDF], ignore_index=True)\n",
        "\n",
        "  def divideData(self, percent, side):\n",
        "    if side == 'start':\n",
        "      return self.frame.loc[:len(self.frame)*percent], self.frame.loc[:len(self.frame)*percent]['Średnia ocen widzow']\n",
        "    elif side == 'end':\n",
        "      return self.frame.loc[len(self.frame)*percent:], self.frame.loc[len(self.frame)*percent:]['Średnia ocen widzow']\n",
        "\n",
        "\n",
        "  def _grabLinks(self, limit):\n",
        "    sitemap = requests.get('https://www.rottentomatoes.com/sitemap.xml').text\n",
        "    usableLinks = []\n",
        "\n",
        "    for maplink in re.findall('<loc>(.*?)</loc>', sitemap):\n",
        "\n",
        "      moviesList = requests.get(maplink).text\n",
        "\n",
        "      for link in re.findall('<loc>(.*?)</loc>', moviesList):\n",
        "        #zapisz tylko 'przydatne' linki\n",
        "        if re.search('(/pictures/|/trailers/)', link) is None:\n",
        "          usableLinks.append(link)\n",
        "          if (limit > 0 and len(usableLinks) >= limit):\n",
        "            return usableLinks\n",
        "    return usableLinks\n",
        "\n",
        "\n",
        "  def _getDataFrame(self, link):\n",
        "    try:\n",
        "      #pobieranie tesktu ze strony\n",
        "      strona = requests.get(link).text\n",
        "\n",
        "      j = re.findall('<script type=\"application/ld\\+json\">(.*?)</script>', strona, re.M | re.S)\n",
        "      if j is None:\n",
        "        raise IndexError(\"brak danych json!\")\n",
        "      if len(j) == 0:\n",
        "        raise IndexError(\"pusty json!\")\n",
        "\n",
        "      data = json.loads(j[0].strip())\n",
        "\n",
        "\n",
        "      #tytul:\n",
        "      tytul = data['name']\n",
        "\n",
        "      #gatunek:\n",
        "      gatunek = data['genre']\n",
        "\n",
        "      #autor:\n",
        "      autorzy = []\n",
        "      for autor in data['author']:\n",
        "        autorzy.append(autor['name'])\n",
        "\n",
        "      #reżyserowie:\n",
        "      rezyserowie = []\n",
        "      for rezyser in data['director']:\n",
        "        rezyserowie.append(rezyser['name'])\n",
        "\n",
        "      #wydawca:\n",
        "      wydawca = data['productionCompany']['name']\n",
        "\n",
        "      #premiera:\n",
        "      premiera = re.findall( r'<time datetime=\\\"(\\d.*?)T\\d\\d', strona, re.S|re.M)\n",
        "      # zwraca coś takiego: 2019-12-19 (rok-miesiąc-dzień), konwersja w pythonie:\n",
        "      premiera = datetime.datetime.strptime(premiera[0], \"%Y-%m-%d\")\n",
        "\n",
        "      #długość:\n",
        "      dlugosc = re.findall( r'time datetime=\\\"P(\\d{1,3})M', strona, re.S|re.M)\n",
        "      if len(dlugosc) == 0:\n",
        "        raise IndexError(\"brak dlugosci\")\n",
        "      dlugosc = int(dlugosc[0])\n",
        "\n",
        "      #obsada:\n",
        "      obsada = []\n",
        "      for aktor in data['actors']:\n",
        "        obsada.append(aktor['name'])\n",
        "      if len(obsada) == 0:\n",
        "        raise IndexError(\"brak obsady\")\n",
        "\n",
        "      #średnia ocen (rotten tomato ma procentowy wynik):\n",
        "      srednia_ocen = re.findall( r'mop-ratings-wrap__percentage\\\">\\s+(\\d{1,3})%', strona, re.S|re.M)\n",
        "      if len(srednia_ocen) == 0:\n",
        "        raise IndexError(\"brak sredniej ocen!\")\n",
        "      srednia_krytykow = int(srednia_ocen[0])\n",
        "      srednia_widzow = int(srednia_ocen[1])\n",
        "\n",
        "      #ilość ocen:\n",
        "      #dla krytyków:\n",
        "      ilosc_ocen_krytykow = re.findall( r'<small class=\\\"mop-ratings-wrap__text--small\\\">\\s+(\\d*)', strona, re.S|re.M)\n",
        "      if len(ilosc_ocen_krytykow) == 0:\n",
        "        raise IndexError(\"brak ocen krytykow!\")\n",
        "      ilosc_ocen_krytykow = int(ilosc_ocen_krytykow[0])\n",
        "      #dla widzów:\n",
        "      ilosc_ocen_widzow = re.findall( r'(?:Verified|User) Ratings: (.*?)<', strona, re.S|re.M)\n",
        "      if len(ilosc_ocen_widzow) == 0:\n",
        "        raise IndexError(\"brak ocen widzow\")\n",
        "      ilosc_ocen_widzow = ilosc_ocen_widzow[0].replace(',', '')\n",
        "      ilosc_ocen_widzow = int(ilosc_ocen_widzow)\n",
        "\n",
        "      lista = [[tytul, gatunek, autorzy, rezyserowie, wydawca, premiera, dlugosc, obsada, srednia_krytykow, ilosc_ocen_krytykow, srednia_widzow, ilosc_ocen_widzow]]\n",
        "      return pd.DataFrame(lista, columns=['Tytuł', 'Gatunek', 'Autorzy', 'Reżyserowie', 'Wydawca', 'Premiera', 'Długość', 'Obsada', 'Średnia ocen krytyków', 'Ilosc ocen krytykow', 'Średnia ocen widzow', 'Ilosc ocen widzow'])\n",
        "    except ValueError as ve:\n",
        "      print(ve, link)\n",
        "    except IndexError as ie:\n",
        "      print(ie, link)\n",
        "    except KeyboardInterrupt:\n",
        "      sys.exit(\"awaryjne hamowanie...\")\n",
        "    except:\n",
        "      print(\"problem przy linku:\", link, \"error:\", sys.exc_info()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb7dwbI3caL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = Data()\n",
        "d.createData(3334)\n",
        "d.frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHleqcXcbDmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d.frame.to_json(\"filmy.json\", orient='split')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uBYUzJN9mCZ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1AZUQ3fb7c6",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#Przygotowanie danych (wczytanych z pliku)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNTPWwT-b74Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "d = Data()\n",
        "d.frame = pd.read_json(\"filmy.json\", orient='split')\n",
        "d.frame = d.frame.sample(frac=1).reset_index(drop=True) #mieszanie kolejności\n",
        "\n",
        "data, results = d.divideData(0.7, 'start')\n",
        "tests, needed = d.divideData(0.7, 'end')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haNgZMiW4Ewe",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsaNPWdsah18",
        "colab_type": "code",
        "outputId": "18cd3387-e7f0-4dd2-b66f-63541fa60afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn import preprocessing\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "class Tokenizer:\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    self.le = preprocessing.LabelEncoder()\n",
        "\n",
        "  def getGenres(self):\n",
        "    results = []\n",
        "    for items in self.data.frame['Gatunek']:\n",
        "      for arrays in items:\n",
        "        for word in nltk.word_tokenize(arrays):\n",
        "          results.append(word)\n",
        "    return self.le.fit(results).classes_\n",
        "\n",
        "  def getAuthors(self):\n",
        "    return self.le.fit(self._flattenList('Autorzy')).classes_\n",
        "\n",
        "  def getDirectors(self):\n",
        "    return self.le.fit(self._flattenList('Reżyserowie')).classes_\n",
        "\n",
        "  def getProducers(self):\n",
        "    return self.le.fit(self._getStrings('Wydawca')).classes_\n",
        "\n",
        "  def getActors(self):\n",
        "    return self.le.fit(self._flattenList('Obsada')).classes_\n",
        "    \n",
        "  def _flattenList(self, name):\n",
        "    flattened = []\n",
        "    for word in self.data.frame[name]:\n",
        "      flattened += word\n",
        "    return flattened    \n",
        "\n",
        "  def _getStrings(self, name):\n",
        "    results = []\n",
        "    for items in self.data.frame[name]:\n",
        "      results.append(items)\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL7YQvk59gqj",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mlf6EHMatzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn import tree\n",
        "from nltk import word_tokenize\n",
        "import numpy as np\n",
        "\n",
        "class ML:\n",
        "  def __init__(self):\n",
        "    self.clf = tree.DecisionTreeClassifier()\n",
        "    self.tokens = Tokenizer(d)\n",
        "    self.predictions = []\n",
        "    self.usedData = []\n",
        "\n",
        "\n",
        "  def teach(self, data, results):\n",
        "    self.usedData = self._cleanData(data)\n",
        "    self.clf.fit(self.usedData, results)\n",
        "\n",
        "  def predict(self, data, results):\n",
        "    self.predictions = self.clf.predict(self._cleanData(data))\n",
        "  \n",
        "\n",
        "  def _cleanData(self, data):\n",
        "    data = data.reset_index(drop=True)\n",
        "    data = self._oneHot(data)\n",
        "    return data.drop(['Tytuł', 'Gatunek', 'Autorzy', 'Reżyserowie', 'Wydawca', 'Obsada', 'Średnia ocen widzow'], axis=1)\n",
        "\n",
        "  def _oneHot(self, data):\n",
        "    genres = self.tokens.getGenres()\n",
        "    producers = self.tokens.getProducers()\n",
        "    actors = self.tokens.getActors()\n",
        "    authors = self.tokens.getAuthors()\n",
        "\n",
        "    for x in range(len(data)):\n",
        "      #przerób tablice gatunków na słowa\n",
        "      words = []\n",
        "      for g in data.at[x, 'Gatunek']:\n",
        "        for word in word_tokenize(g):\n",
        "          words.append(word)\n",
        "      for genre in genres:\n",
        "        #sprawdź które słowa występują w data\n",
        "        if genre in words:\n",
        "          data.at[x, genre] = 1\n",
        "        else:\n",
        "          data.at[x, genre] = 0\n",
        "      \n",
        "      self._hotInsert(data, x, producers, 'Wydawca')\n",
        "      self._hotInsert(data, x, authors, 'Autorzy')\n",
        "      # self._hotInsert(data, x, actors, 'Obsada')\n",
        "      \n",
        "\n",
        "    return data\n",
        "\n",
        "  def _hotInsert(self, data, index, arr, name):\n",
        "    for word in arr:\n",
        "      if word in data.at[index, name]:\n",
        "        data.at[index, word] = 1\n",
        "      else:\n",
        "        data.at[index, word] = 0\n",
        "\n",
        "  def score(self):\n",
        "    deviant = []\n",
        "    for i in range(len(self.predictions)):\n",
        "      deviant.append(abs(needed.iloc[i] - self.predictions[i]))\n",
        "\n",
        "    print('srednia roznica ocen:', np.mean(deviant))\n",
        "    a = [0,0,0,0]\n",
        "    for dev in deviant:\n",
        "      if dev < 5:\n",
        "        a[0] += 1\n",
        "      elif dev < 15:\n",
        "        a[1] += 1\n",
        "      elif dev < 20:\n",
        "        a[2] += 1\n",
        "      else:\n",
        "        a[3] += 1\n",
        "    print(\"różnica do 5%:\", a[0])\n",
        "    print(\"różnica do 15%:\", a[1])\n",
        "    print(\"różnica do 20%:\", a[2])\n",
        "    print(\"różnica powyżej 20%:\", a[3])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTydU2rVfKSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ml = ML()\n",
        "ml.teach(data, results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHuKzFKpgaia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ml.predict(tests, needed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v5bU2JNlGtb",
        "colab_type": "code",
        "outputId": "99ab4ffe-1fab-4cc7-f760-01446de08590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ml.score()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "srednia roznica ocen: 14.393120393120393\n",
            "różnica do 5%: 171\n",
            "różnica do 15%: 310\n",
            "różnica do 20%: 113\n",
            "różnica powyżej 20%: 220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIPcwfNUjIv0",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#Testy jednostkowe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqv-00ZFjUPQ",
        "colab_type": "code",
        "outputId": "48453100-a0e8-4dd2-e4c0-2106026b96db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import unittest\n",
        "import pandas as pd\n",
        "\n",
        "class TestPageParser(unittest.TestCase):\n",
        "  def testParser(self):\n",
        "    pars = Data()\n",
        "    correctResult = pd.DataFrame([[\"Star Wars: Episode III - Revenge of the Sith\",['Action & Adventure', 'Drama', 'Science Fiction & Fantasy'],['George Lucas'],['George Lucas'],\"20th Century Fox\",datetime.datetime.strptime('2005-05-18', '%Y-%m-%d'),140,['Ewan McGregor', 'Natalie Portman', 'Hayden Christensen', 'Ian McDiarmid', 'Samuel L. Jackson', 'Jimmy Smits', 'Frank Oz', 'Anthony Daniels', 'Christopher Lee', 'Keisha Castle-Hughes', 'James Earl Jones', 'Silas Carson', \"Jay Laga'aia\", \"Jay Lagai'aia\", 'Bruce Spence', 'Wayne Pygram', 'Temuera Morrison', 'David Bowers (II) ', 'Mimi Daraphet', 'Paul Davies', 'Oliver Ford Davies', 'Ahmed Best', 'Sandi Finlay', 'Nalini Krishan', 'Rohan Nichol', 'Jeremy Bulloch', 'Amanda Lucas', 'Mary Oyaya', 'Kenny Baker', 'Matt Sloan', 'Orli Shoshan', 'Sandy Thompson', 'Peter Mayhew', 'Marty Wetherill', 'Rebecca Jackson Mendoza', 'Joel Edgerton', 'Bonnie Maree Piesse', 'Jett Lucas', 'Chantal Freer', 'Tux Akindoyeni', 'Matt Rowan', 'Kenji Oates', 'Amy Allen', 'Graeme Blundell', 'Trisha Noble', 'Claudia Karvan', 'Keira Wingate', 'Hayley Mooy', 'Bonnie Piesse', 'Sandy Finlay', 'Bai Ling', 'Katie Lucas', \"Genevieve O'Reilly\", 'Warren Owens', 'Kee Chan', 'Christopher Kirby', 'Kristy Wright', 'Coinneach Alexander', 'Mousy McCallum', 'Michael Kingma', 'Axel Dench', 'Steven Foy', 'Julian Khazzouh', 'Michael James Rowland', 'Bodie \"Tihoi\" Taylor', 'David Stiff', 'Robert Cope', 'Matthew Wood', 'Rena Owen'],80,299,66,33683838]], columns=['Tytuł', 'Gatunek', 'Autorzy', 'Reżyserowie', 'Wydawca', 'Premiera', 'Długość', 'Obsada', 'Średnia ocen krytyków', 'Ilosc ocen krytykow', 'Średnia ocen widzow', 'Ilosc ocen widzow'])\n",
        "    testedResult = pars._getDataFrame('https://www.rottentomatoes.com/m/star_wars_episode_iii_revenge_of_the_sith')\n",
        "    pd.testing.assert_frame_equal(correctResult, testedResult)\n",
        "    \n",
        "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.106s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7f5a67637780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}